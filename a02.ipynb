{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "06fa1705",
   "metadata": {},
   "source": [
    "# Deep Learning: Assignment 2"
   ]
  },
  {
   "cell_type": "code",
   "id": "f364fb03",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:13.977679Z",
     "start_time": "2024-04-26T20:49:11.582507Z"
    }
   },
   "source": [
    "# Define imports & defaults\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "\n",
    "# import helper functions\n",
    "import os\n",
    "import sys\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from a02helper import *\n",
    "\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.manual_seed(0)  # ensure reproducibility\n",
    "np.random.seed(0)\n",
    "\n",
    "MAX_SEQ_LEN = 200\n",
    "BATCH_SIZE = 32"
   ],
   "outputs": [],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "237ac6da",
   "metadata": {},
   "source": [
    "## Task 1: Datasets"
   ]
  },
  {
   "cell_type": "code",
   "id": "4325298a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:14.079029Z",
     "start_time": "2024-04-26T20:49:13.979178Z"
    }
   },
   "source": [
    "import string\n",
    "from torchtext.vocab import vocab\n",
    "from torchtext.data import get_tokenizer\n",
    "\n",
    "class ReviewsDataset(Dataset):\n",
    "    def __init__(\n",
    "        self,\n",
    "        reviews_file=\"data/reviews_small.txt\",\n",
    "        labels_file=\"data/labels_small.txt\",\n",
    "        use_vocab=False,\n",
    "    ):\n",
    "        \"\"\"\n",
    "        A dataset of movie reviews and their labels.\n",
    "\n",
    "        Args:\n",
    "            reviews_file: the reviews file\n",
    "            labels_file:  the labels file\n",
    "            use_vocab: if True, yield reviews in a numerical representation\n",
    "        \"\"\"\n",
    "        # Load data from filesystem\n",
    "        with open(reviews_file) as f:\n",
    "            raw_reviews = f.readlines()\n",
    "\n",
    "        with open(labels_file) as f:\n",
    "            raw_labels = f.readlines()\n",
    "\n",
    "        # Preprocessing and store (in memory)\n",
    "        self._reviews = self._preprocess_reviews(raw_reviews)\n",
    "        self._labels = self._preprocess_labels(raw_labels)\n",
    "\n",
    "        # Build vocabulary\n",
    "        self.vocab = None\n",
    "        if use_vocab:\n",
    "            from torchtext.vocab import build_vocab_from_iterator\n",
    "            self.vocab = build_vocab_from_iterator(\n",
    "                self._reviews, specials=[\"<pad>\"]  # will get token id 0\n",
    "            )\n",
    "\n",
    "    def __len__(self):\n",
    "        \"\"\"Returns the length of the dataset.\"\"\"\n",
    "        return len(self._reviews)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        \"\"\"\n",
    "        Returns a tuple of a preprocessed review and the corresponding label. If the\n",
    "        vocabulary is enabled, returns a numerical representation of the review.\n",
    "\n",
    "        Args:\n",
    "            idx: a single index\n",
    "        Returns: a (review, label) tuple\n",
    "        \"\"\"\n",
    "        review = self._reviews[idx]\n",
    "        label = self._labels[idx]        \n",
    "        if self.vocab:\n",
    "            review_ids = [self.vocab.get_stoi()[token] for token in review]\n",
    "            return review_ids, label\n",
    "        else:\n",
    "            return review, label\n",
    "\n",
    "    def _preprocess_reviews(self, raw_reviews):\n",
    "        \"\"\"\n",
    "        Applies two kinds of preprocessing:\n",
    "\n",
    "        (i) Apply the \"basic_english\" tokenizer from the torchtext library to\n",
    "        transform every review into a list of normalized tokens (cf.\n",
    "        https://pytorch.org/text/stable/data_utils.html#get-tokenizer).\n",
    "\n",
    "        (ii) Remove punctuation (cf.\n",
    "        https://docs.python.org/3/library/string.html#string.punctuation).\n",
    "\n",
    "        Returns: list of tokenized reviews\n",
    "        \"\"\"\n",
    "        tokenizer = get_tokenizer(\"basic_english\")\n",
    "        tokenized_list = []\n",
    "        for review in range (len(raw_reviews)):\n",
    "            temp_str = raw_reviews[review].translate(str.maketrans(\"\", \"\", string.punctuation))\n",
    "            temp_str = tokenizer(temp_str)\n",
    "            tokenized_list.append(temp_str)\n",
    "        return tokenized_list\n",
    "\n",
    "    def _preprocess_labels(self, raw_labels):\n",
    "        \"\"\"\n",
    "        Transform raw labels into integers, where 1=\"positive\" and 0 otherwise.\n",
    "\n",
    "        Returns: list of labels\n",
    "        \"\"\"\n",
    "        # Hint: You can remove leading and trailing whitespace from the raw labels using\n",
    "        # the strip() method.\n",
    "        preprocessed_labels_list = []\n",
    "        for label in raw_labels:\n",
    "            label = label.strip()\n",
    "            if label == \"positive\":\n",
    "                preprocessed_labels_list.append(1)\n",
    "            else:\n",
    "                preprocessed_labels_list.append(0)\n",
    "        return preprocessed_labels_list"
   ],
   "outputs": [],
   "execution_count": 2
  },
  {
   "cell_type": "code",
   "id": "fcdcdf34",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:14.386153Z",
     "start_time": "2024-04-26T20:49:14.080322Z"
    }
   },
   "source": [
    "# Test your code (without vocabulary).\n",
    "dataset = ReviewsDataset()\n",
    "print(dataset[0])\n",
    "\n",
    "# Should yield:\n",
    "# (['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', ... ], 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(['bromwell', 'high', 'is', 'a', 'cartoon', 'comedy', 'it', 'ran', 'at', 'the', 'same', 'time', 'as', 'some', 'other', 'programs', 'about', 'school', 'life', 'such', 'as', 'teachers', 'my', 'years', 'in', 'the', 'teaching', 'profession', 'lead', 'me', 'to', 'believe', 'that', 'bromwell', 'high', 's', 'satire', 'is', 'much', 'closer', 'to', 'reality', 'than', 'is', 'teachers', 'the', 'scramble', 'to', 'survive', 'financially', 'the', 'insightful', 'students', 'who', 'can', 'see', 'right', 'through', 'their', 'pathetic', 'teachers', 'pomp', 'the', 'pettiness', 'of', 'the', 'whole', 'situation', 'all', 'remind', 'me', 'of', 'the', 'schools', 'i', 'knew', 'and', 'their', 'students', 'when', 'i', 'saw', 'the', 'episode', 'in', 'which', 'a', 'student', 'repeatedly', 'tried', 'to', 'burn', 'down', 'the', 'school', 'i', 'immediately', 'recalled', 'at', 'high', 'a', 'classic', 'line', 'inspector', 'i', 'm', 'here', 'to', 'sack', 'one', 'of', 'your', 'teachers', 'student', 'welcome', 'to', 'bromwell', 'high', 'i', 'expect', 'that', 'many', 'adults', 'of', 'my', 'age', 'think', 'that', 'bromwell', 'high', 'is', 'far', 'fetched', 'what', 'a', 'pity', 'that', 'it', 'isn', 't'], 1)\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "id": "ebcd9318",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:16.536459Z",
     "start_time": "2024-04-26T20:49:14.387036Z"
    }
   },
   "source": [
    "# Test your code (with vocabulary).\n",
    "dataset = ReviewsDataset(use_vocab=True)\n",
    "print(dataset[0])\n",
    "\n",
    "# Should yield:\n",
    "# ([10661, 307, 6, 3, 1177, 202, 8,  ... ], 1)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "([10661, 307, 6, 3, 1177, 202, 8, 2248, 33, 1, 168, 56, 15, 49, 85, 8902, 43, 422, 122, 140, 15, 3234, 59, 144, 9, 1, 5504, 6267, 454, 72, 5, 260, 12, 10661, 307, 13, 2060, 6, 73, 2780, 5, 692, 76, 6, 3234, 1, 29527, 5, 1730, 7117, 1, 6161, 1726, 36, 52, 68, 212, 143, 63, 1409, 3234, 17974, 1, 28056, 4, 1, 221, 758, 31, 2748, 72, 4, 1, 6311, 10, 731, 2, 63, 1726, 54, 10, 208, 1, 321, 9, 64, 3, 1601, 4042, 743, 5, 2853, 187, 1, 422, 10, 1254, 10116, 33, 307, 3, 380, 322, 6162, 10, 135, 136, 5, 10172, 30, 4, 134, 3234, 1601, 2545, 5, 10661, 307, 10, 529, 12, 113, 1841, 4, 59, 676, 103, 12, 10661, 307, 6, 227, 4163, 48, 3, 2201, 12, 8, 231, 21], 1)\n"
     ]
    }
   ],
   "execution_count": 4
  },
  {
   "cell_type": "markdown",
   "id": "025e9e65",
   "metadata": {},
   "source": [
    "## Task 2: Data Loaders"
   ]
  },
  {
   "cell_type": "code",
   "id": "2ca2dc4e",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:17.047619Z",
     "start_time": "2024-04-26T20:49:16.538858Z"
    }
   },
   "source": [
    "# Split dataset into training, validation, and test subsets\n",
    "dataset = ReviewsDataset(use_vocab=True)\n",
    "train_set, val_set, test_set = torch.utils.data.random_split(\n",
    "    dataset, [0.8, 0.1, 0.1], generator=torch.Generator().manual_seed(123)\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 5
  },
  {
   "cell_type": "markdown",
   "id": "51540bfb",
   "metadata": {},
   "source": [
    "### Task 2a"
   ]
  },
  {
   "cell_type": "code",
   "id": "973f2213",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:17.050688Z",
     "start_time": "2024-04-26T20:49:17.048425Z"
    }
   },
   "source": [
    "# Example usage of a data loader\n",
    "dataloader = DataLoader(\n",
    "    val_set,  # a dataset\n",
    "    1,  # desired batch size\n",
    "    False,  # whether to randomly shuffle the dataset\n",
    "    num_workers=0,  # number of workers that construct batches in parallel\n",
    ")"
   ],
   "outputs": [],
   "execution_count": 6
  },
  {
   "cell_type": "code",
   "id": "efe7905a",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:18.284676Z",
     "start_time": "2024-04-26T20:49:17.051546Z"
    }
   },
   "source": [
    "# Let's print the first batch\n",
    "batch = next(iter(dataloader))\n",
    "print(batch)\n",
    "# [[tensor([11]), tensor([6]), tensor([1]), ...], tensor([0])]"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[tensor([11]), tensor([6]), tensor([1]), tensor([1037]), tensor([6578]), tensor([4]), tensor([10]), tensor([89]), tensor([120]), tensor([48]), tensor([163]), tensor([47]), tensor([6]), tensor([27]), tensor([342]), tensor([4]), tensor([2228]), tensor([140]), tensor([3]), tensor([186]), tensor([1466]), tensor([1]), tensor([771]), tensor([26]), tensor([78]), tensor([1459]), tensor([200]), tensor([1101]), tensor([1]), tensor([66]), tensor([26]), tensor([78]), tensor([5199]), tensor([5]), tensor([2288]), tensor([1]), tensor([7861]), tensor([6591]), tensor([2]), tensor([83]), tensor([2446]), tensor([25]), tensor([1]), tensor([182]), tensor([2756]), tensor([2520]), tensor([34]), tensor([1]), tensor([145]), tensor([8]), tensor([13]), tensor([39]), tensor([290]), tensor([25]), tensor([252]), tensor([14480]), tensor([32]), tensor([52]), tensor([497]), tensor([9]), tensor([223]), tensor([1]), tensor([3254]), tensor([25]), tensor([937]), tensor([2]), tensor([153]), tensor([568]), tensor([5]), tensor([91]), tensor([2]), tensor([30]), tensor([388]), tensor([1110]), tensor([17]), tensor([80]), tensor([62]), tensor([1]), tensor([119]), tensor([255]), tensor([14]), tensor([34]), tensor([2632]), tensor([1539]), tensor([133]), tensor([28]), tensor([6]), tensor([31]), tensor([56]), tensor([33]), tensor([27]), tensor([119]), tensor([413]), tensor([1]), tensor([230]), tensor([4]), tensor([1036]), tensor([17]), tensor([3]), tensor([738]), tensor([552]), tensor([1305]), tensor([11189]), tensor([14923]), tensor([6]), tensor([88]), tensor([203]), tensor([3]), tensor([50]), tensor([283]), tensor([19]), tensor([1]), tensor([27078]), tensor([44]), tensor([683]), tensor([8])], tensor([0])]\n"
     ]
    }
   ],
   "execution_count": 7
  },
  {
   "metadata": {
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:22.557166Z",
     "start_time": "2024-04-26T20:49:18.285750Z"
    }
   },
   "cell_type": "code",
   "source": [
    "print(len(val_set[0][0]))\n",
    "print(len(val_set[1][0]))\n",
    "print(len(val_set[2][0]))"
   ],
   "id": "5f21fd98c1017681",
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n",
      "158\n",
      "131\n"
     ]
    }
   ],
   "execution_count": 8
  },
  {
   "metadata": {},
   "cell_type": "markdown",
   "source": "Having different length of the input reviews, during the batch size, it will require those input sentence are having the same length to represent their representation",
   "id": "561853c420859621"
  },
  {
   "cell_type": "markdown",
   "id": "7160793e",
   "metadata": {},
   "source": [
    "### Task 2b"
   ]
  },
  {
   "cell_type": "code",
   "id": "f91c149f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:22.586831Z",
     "start_time": "2024-04-26T20:49:22.566697Z"
    }
   },
   "source": [
    "def review_collate_fn(raw_batch):\n",
    "    \"\"\"Prepare batches of reviews from a review dataset.\n",
    "\n",
    "    Args:\n",
    "        raw_batch: collection of (review, label)-tuples from a ReviewDataset\n",
    "\n",
    "    Returns: a tuple (review x token id tensor, label tensor) of sizes\n",
    "    batch_size*MAX_SEQ_LEN and batch_size, respectively.\n",
    "\n",
    "    \"\"\"\n",
    "    reviews, labels = zip(*raw_batch)\n",
    "    padded_reviews = torch.zeros(len(reviews), MAX_SEQ_LEN, dtype=torch.long)\n",
    "    \n",
    "    for i, review in enumerate (reviews):\n",
    "        if len(review) <= MAX_SEQ_LEN:\n",
    "            padded_reviews[i, :len(review)] = torch.tensor(review)\n",
    "        else:\n",
    "            padded_reviews[i, :] = torch.tensor(review[:MAX_SEQ_LEN]).clone().detach()\n",
    "    label_tensor = torch.tensor(labels, dtype=torch.long)\n",
    "    return padded_reviews, label_tensor"
   ],
   "outputs": [],
   "execution_count": 9
  },
  {
   "cell_type": "code",
   "id": "31b88d4b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:22.619314Z",
     "start_time": "2024-04-26T20:49:22.588127Z"
    }
   },
   "source": [
    "# Test your function\n",
    "review_collate_fn([([1, 2, 3], 1), (torch.arange(MAX_SEQ_LEN * 2) + 1, 0)])\n",
    "\n",
    "# Should yield:\n",
    "# (tensor([[  1,   2,   3,   0,   0,  ..., 0 ],\n",
    "#          [  1,   2,   3,   4,   5, ..., 200 ]]),\n",
    "#  tensor([1, 0]))"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/2h/v65x911156j8d_r4wnykkqrw0000gn/T/ipykernel_40995/3549971076.py:18: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  padded_reviews[i, :] = torch.tensor(review[:MAX_SEQ_LEN]).clone().detach()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(tensor([[  1,   2,   3,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,   0,\n",
       "            0,   0,   0,   0],\n",
       "         [  1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  12,  13,  14,\n",
       "           15,  16,  17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,\n",
       "           29,  30,  31,  32,  33,  34,  35,  36,  37,  38,  39,  40,  41,  42,\n",
       "           43,  44,  45,  46,  47,  48,  49,  50,  51,  52,  53,  54,  55,  56,\n",
       "           57,  58,  59,  60,  61,  62,  63,  64,  65,  66,  67,  68,  69,  70,\n",
       "           71,  72,  73,  74,  75,  76,  77,  78,  79,  80,  81,  82,  83,  84,\n",
       "           85,  86,  87,  88,  89,  90,  91,  92,  93,  94,  95,  96,  97,  98,\n",
       "           99, 100, 101, 102, 103, 104, 105, 106, 107, 108, 109, 110, 111, 112,\n",
       "          113, 114, 115, 116, 117, 118, 119, 120, 121, 122, 123, 124, 125, 126,\n",
       "          127, 128, 129, 130, 131, 132, 133, 134, 135, 136, 137, 138, 139, 140,\n",
       "          141, 142, 143, 144, 145, 146, 147, 148, 149, 150, 151, 152, 153, 154,\n",
       "          155, 156, 157, 158, 159, 160, 161, 162, 163, 164, 165, 166, 167, 168,\n",
       "          169, 170, 171, 172, 173, 174, 175, 176, 177, 178, 179, 180, 181, 182,\n",
       "          183, 184, 185, 186, 187, 188, 189, 190, 191, 192, 193, 194, 195, 196,\n",
       "          197, 198, 199, 200]]),\n",
       " tensor([1, 0]))"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 10
  },
  {
   "cell_type": "code",
   "id": "51299831",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:49:22.623646Z",
     "start_time": "2024-04-26T20:49:22.620377Z"
    }
   },
   "source": [
    "# Create the data loaders (with shuffling for training data -> randomization)\n",
    "train_loader = DataLoader(train_set, BATCH_SIZE, True, collate_fn=review_collate_fn)\n",
    "val_loader = DataLoader(val_set, BATCH_SIZE, False, collate_fn=review_collate_fn)\n",
    "test_loader = DataLoader(test_set, BATCH_SIZE, False, collate_fn=review_collate_fn)"
   ],
   "outputs": [],
   "execution_count": 11
  },
  {
   "cell_type": "code",
   "id": "a6092fc9",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:50:25.831690Z",
     "start_time": "2024-04-26T20:49:22.624781Z"
    }
   },
   "source": [
    "# Let's print the first batch\n",
    "batch = next(iter(val_loader))\n",
    "print(batch)\n",
    "\n",
    "\n",
    "# (tensor([[   11,     6,     1,  ...,     0,     0,     0],\n",
    "#         [   11,   170,  2220,  ...,     0,     0,     0],\n",
    "#         [   48,     3, 30376,  ...,     0,     0,     0],\n",
    "#         ...,\n",
    "#         [  176,    56,    10,  ...,     0,     0,     0],\n",
    "#         [  239,   534,  1404,  ...,    44,   120,     1],\n",
    "#         [ 2954, 15576,     6,  ...,  2678,    65,     1]]),\n",
    "#  tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
    "#         0, 0, 0, 1, 1, 1, 0, 0]))"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(tensor([[   11,     6,     1,  ...,     0,     0,     0],\n",
      "        [   11,   170,  2220,  ...,     0,     0,     0],\n",
      "        [   48,     3, 30376,  ...,     0,     0,     0],\n",
      "        ...,\n",
      "        [  176,    56,    10,  ...,     0,     0,     0],\n",
      "        [  239,   534,  1404,  ...,    44,   120,     1],\n",
      "        [ 2954, 15576,     6,  ...,  2678,    65,     1]]), tensor([0, 1, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0, 1, 0, 0, 1,\n",
      "        0, 0, 0, 1, 1, 1, 0, 0]))\n"
     ]
    }
   ],
   "execution_count": 12
  },
  {
   "cell_type": "markdown",
   "id": "0a04630d",
   "metadata": {},
   "source": [
    "## Task 3: Recurrent Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "id": "93bcc6e0",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:50:25.843425Z",
     "start_time": "2024-04-26T20:50:25.833232Z"
    }
   },
   "source": [
    "class SimpleLSTM(nn.Module):\n",
    "    def __init__(\n",
    "        self, vocab_size, embedding_dim, hidden_dim, num_layers=1, cell_dropout=0.0\n",
    "    ):\n",
    "        \"\"\"\n",
    "        Initializes the model by setting up the layers.\n",
    "\n",
    "        Args:\n",
    "            vocab_size: number of unique words in the reviews\n",
    "            embedding_dim: size of the embeddings\n",
    "            hidden_dim: dimension of the LSTM output\n",
    "            num_layers: number of LSTM layers\n",
    "            cell_dropout: dropout applied between the LSTM layers\n",
    "                          (provide to LSTM constructor as dropout argument)\n",
    "        \"\"\"\n",
    "        super(SimpleLSTM, self).__init__()\n",
    "        self.num_layers = num_layers\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.word_embeddings = nn.Embedding(vocab_size, embedding_dim)\n",
    "        self.lstm = nn.LSTM(embedding_dim, hidden_dim, batch_first = True, num_layers=self.num_layers, dropout=cell_dropout)\n",
    "        self.cell_dropout = cell_dropout\n",
    "        self.fc = nn.Linear(self.hidden_dim, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "\n",
    "    def forward(self, x):\n",
    "        \"\"\"\n",
    "        Performs a forward pass of the model on some input and hidden state.\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        x: batch as a (batch_size, sequence_length) tensor\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        Probability of positive class and the last output of the LSTM.\n",
    "        \"\"\"\n",
    "        hidden = self.init_hidden(len(x))\n",
    "        embeddings = self.word_embeddings(x)\n",
    "        outputs, (h_n, c_n) = self.lstm(embeddings, hidden)\n",
    "        last_output = h_n[-1, :, :]\n",
    "        logits = self.fc(last_output)\n",
    "        predictions = self.sigmoid(logits)\n",
    "        return predictions, last_output\n",
    "\n",
    "    def init_hidden(self, batch_size):\n",
    "        \"\"\"Initialize hidden states.\n",
    "\n",
    "        Returns a tuple of two num_layers x batch_size x hidden_dim tensors (one for\n",
    "        initial cell states, one for initial hidden states) consisting of all zeros.\n",
    "        \"\"\"\n",
    "        # Note: ensure that the returned tensors are located on DEVICE.\n",
    "        device = self.word_embeddings.weight.device\n",
    "        h_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        c_0 = torch.zeros(self.num_layers, batch_size, self.hidden_dim, device=device)\n",
    "        return h_0, c_0\n",
    "\n",
    "\n",
    "# Test constructor\n",
    "model = SimpleLSTM(50, 10, 32, 2, 0.1).to(DEVICE)\n",
    "print(model)\n",
    "\n",
    "# Should give:\n",
    "# SimpleLSTM(\n",
    "#   (embedding): Embedding(50, 10)\n",
    "#   (lstm): LSTM(10, 32, num_layers=2, batch_first=True, dropout=0.1)\n",
    "#   (fc): Linear(in_features=32, out_features=1, bias=True)\n",
    "#   (sigmoid): Sigmoid()\n",
    "# )"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SimpleLSTM(\n",
      "  (word_embeddings): Embedding(50, 10)\n",
      "  (lstm): LSTM(10, 32, num_layers=2, batch_first=True, dropout=0.1)\n",
      "  (fc): Linear(in_features=32, out_features=1, bias=True)\n",
      "  (sigmoid): Sigmoid()\n",
      ")\n"
     ]
    }
   ],
   "execution_count": 13
  },
  {
   "cell_type": "code",
   "id": "5b610db5",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:50:25.875124Z",
     "start_time": "2024-04-26T20:50:25.846331Z"
    }
   },
   "source": [
    "# Test forward pass\n",
    "model = SimpleLSTM(50, 10, 32, 2).to(DEVICE)\n",
    "dummy_data = torch.arange(30, dtype=torch.int, device=DEVICE).reshape(3, 10)\n",
    "\n",
    "# fix model parameters\n",
    "for key in model.state_dict():\n",
    "    model.state_dict()[key][:] = 0.1\n",
    "probs, states = model(dummy_data)\n",
    "print(probs)\n",
    "print(states)\n",
    "\n",
    "\n",
    "# tensor([[0.9643],\n",
    "#         [0.9643],\n",
    "#         [0.9643]], device='cuda:0 or cpu', grad_fn=<SigmoidBackward0>)\n",
    "# tensor([[0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985],\n",
    "#         [0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985],\n",
    "#         [0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
    "#          0.9985, 0.9985, 0.9985, 0.9985, 0.9985]], device='cuda:0 or cpu',\n",
    "#        grad_fn=<SliceBackward0>)"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0.9643],\n",
      "        [0.9643],\n",
      "        [0.9643]], grad_fn=<SigmoidBackward0>)\n",
      "tensor([[0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985],\n",
      "        [0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985],\n",
      "        [0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985, 0.9985,\n",
      "         0.9985, 0.9985, 0.9985, 0.9985, 0.9985]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "execution_count": 14
  },
  {
   "cell_type": "markdown",
   "id": "1b61465b",
   "metadata": {},
   "source": [
    "### Task 3d"
   ]
  },
  {
   "cell_type": "code",
   "id": "5e32c14d",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T20:50:25.879881Z",
     "start_time": "2024-04-26T20:50:25.875988Z"
    }
   },
   "source": [
    "@torch.no_grad()  # Disables autograd for this function\n",
    "def reviews_eval(\n",
    "    model, eval_loader, label=\"val\", loss_fn=torch.nn.functional.binary_cross_entropy\n",
    "):\n",
    "    model.to(DEVICE)\n",
    "    model.eval()  # sets model to evaluation mode (e.g., relevant for dropout)\n",
    "\n",
    "    total_correct = total_loss = 0\n",
    "    for reviews, labels in eval_loader:\n",
    "        reviews, labels = reviews.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "        # Forward pass: Compute the model's output, reshape it to a vector, and\n",
    "        # then run the provided loss function.\n",
    "        prediction, _ = model(reviews)\n",
    "        prediction = prediction.view(-1)\n",
    "        loss = loss_fn(prediction, labels.float())\n",
    "        \n",
    "        # Eval stats: Add loss to total_loss and number of correct predictions to\n",
    "        # total_correct.\n",
    "        total_loss = total_loss + loss.item()\n",
    "        prediction_class = torch.round(prediction)\n",
    "        correct = (prediction_class == labels).sum().item()\n",
    "        total_correct = total_correct + correct\n",
    "\n",
    "    print(\n",
    "        f\"            \"\n",
    "        f\"{label} accuracy: {total_correct / len(eval_loader.dataset):.4f}\\t\"\n",
    "        f\"{label} loss: {total_loss / len(eval_loader):.4f}\"\n",
    "    )"
   ],
   "outputs": [],
   "execution_count": 15
  },
  {
   "cell_type": "code",
   "id": "db972e44",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    },
    "ExecuteTime": {
     "start_time": "2024-04-26T20:50:25.880688Z"
    }
   },
   "source": [
    "# Test your implementation\n",
    "model = SimpleLSTM(len(dataset.vocab), 10, 10, 1, 0).to(DEVICE)\n",
    "reviews_eval(model, val_loader)\n",
    "\n",
    "# Should yield with different but similar numbers:\n",
    "#             val accuracy: 0.5100\tval loss: 0.6928"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "68cc6ec6",
   "metadata": {},
   "source": [
    "### Task 3e"
   ]
  },
  {
   "cell_type": "code",
   "id": "288bbb97",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "def reviews_train(\n",
    "    model,\n",
    "    train_loader,\n",
    "    val_loader,\n",
    "    lr=0.01,\n",
    "    epochs=3,\n",
    "    max_norm=5,\n",
    "    loss_fn=torch.nn.functional.binary_cross_entropy,\n",
    "):\n",
    "    \"\"\"\n",
    "    Train a network on the review data\n",
    "\n",
    "    Args:\n",
    "        model: Initialized model\n",
    "        train_loader: Dataloader for the training data\n",
    "        val_loader: Dataloader for the validation data\n",
    "        lr: learning rate\n",
    "        epochs: number of epochs\n",
    "        max_norm: max norm of gradients for gradient clipping\n",
    "        loss_fn: Loss function\n",
    "    \"\"\"\n",
    "    # Send the model's parameters to your accelerator (cuda or cpu)\n",
    "    model = model.to(DEVICE)\n",
    "\n",
    "    # Define optimizer for the parameters which require gradients (cf. Task 5)\n",
    "    optimizer = torch.optim.Adam(\n",
    "        [param for param in model.parameters() if param.requires_grad], lr=lr\n",
    "    )\n",
    "\n",
    "    # Let's go\n",
    "    for epoch in range(epochs):\n",
    "        total_correct = total_loss = 0\n",
    "        for reviews, labels in train_loader:\n",
    "            model.train()\n",
    "\n",
    "            # Send batch to your accelerator\n",
    "            reviews, labels = reviews.to(DEVICE), labels.to(DEVICE)\n",
    "\n",
    "            # Forward pass: Compute the model's output, reshape it to a vector, and then\n",
    "            # run the provided loss function.\n",
    "            prediction, _ = model(reviews)\n",
    "            prediction = prediction.view(-1)\n",
    "            loss = loss_fn(prediction, labels.float())\n",
    "\n",
    "            # Backward pass:\n",
    "            # (i)   Compute the gradients wrt. the loss\n",
    "            # (ii)  Clip the gradients using\n",
    "            #       https://pytorch.org/docs/stable/generated/torch.nn.utils.clip_grad_norm_.html to max_norm\n",
    "            # (iii) Run the optimizer\n",
    "            # (iv)  Clear all accumulated gradients\n",
    "            loss.backward()\n",
    "            torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm = max_norm, norm_type = 2.0)\n",
    "            optimizer.step()\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "\n",
    "            # Compute epoch statistics:\n",
    "            # (i)  Add the loss of this batch to the total_loss\n",
    "            # (ii) Add the number of correct predictions (max prob) to total_correct\n",
    "            total_loss = total_loss + loss.item()\n",
    "            prediction_class = torch.round(prediction)\n",
    "            correct = (prediction_class == labels).sum().item()\n",
    "            total_correct = total_correct + correct\n",
    "\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1:2}\\t\"\n",
    "            f\"train accuracy: {total_correct / len(train_loader.dataset):.4f}\\t\"\n",
    "            f\"train loss: {total_loss / len(train_loader):.4f}\"\n",
    "        )\n",
    "\n",
    "        # now validate\n",
    "        reviews_eval(model, val_loader, loss_fn=loss_fn)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "97e21533",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-26T18:53:49.033256Z",
     "start_time": "2024-04-26T18:23:01.112568Z"
    }
   },
   "source": [
    "# Test your implementation\n",
    "model = SimpleLSTM(len(dataset.vocab), 10, 10, 1).to(DEVICE)\n",
    "reviews_train(model, train_loader, val_loader, epochs=5)\n",
    "\n",
    "# Should yield something like (note: numbers have high variance over runs):\n",
    "# Epoch  1\ttrain accuracy: 0.4994\ttrain loss: 0.6953\n",
    "#             val accuracy: 0.4875\tval loss: 0.6922\n",
    "# Epoch  2\ttrain accuracy: 0.5319\ttrain loss: 0.6885\n",
    "#             val accuracy: 0.5275\tval loss: 0.6861\n",
    "# Epoch  3\ttrain accuracy: 0.6059\ttrain loss: 0.6443\n",
    "#             val accuracy: 0.5400\tval loss: 0.6902\n",
    "# Epoch  4\ttrain accuracy: 0.6863\ttrain loss: 0.5438\n",
    "#             val accuracy: 0.5925\tval loss: 0.7453\n",
    "# Epoch  5\ttrain accuracy: 0.8334\ttrain loss: 0.3875\n",
    "#             val accuracy: 0.7300\tval loss: 0.6310"
   ],
   "outputs": [
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[0;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[0;32mIn[20], line 3\u001B[0m\n\u001B[1;32m      1\u001B[0m \u001B[38;5;66;03m# Test your implementation\u001B[39;00m\n\u001B[1;32m      2\u001B[0m model \u001B[38;5;241m=\u001B[39m SimpleLSTM(\u001B[38;5;28mlen\u001B[39m(dataset\u001B[38;5;241m.\u001B[39mvocab), \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m10\u001B[39m, \u001B[38;5;241m1\u001B[39m)\u001B[38;5;241m.\u001B[39mto(DEVICE)\n\u001B[0;32m----> 3\u001B[0m \u001B[43mreviews_train\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmodel\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mtrain_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mval_loader\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mepochs\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[38;5;241;43m5\u001B[39;49m\u001B[43m)\u001B[49m\n\u001B[1;32m      5\u001B[0m \u001B[38;5;66;03m# Should yield something like (note: numbers have high variance over runs):\u001B[39;00m\n\u001B[1;32m      6\u001B[0m \u001B[38;5;66;03m# Epoch  1\ttrain accuracy: 0.4994\ttrain loss: 0.6953\u001B[39;00m\n\u001B[1;32m      7\u001B[0m \u001B[38;5;66;03m#             val accuracy: 0.4875\tval loss: 0.6922\u001B[39;00m\n\u001B[0;32m   (...)\u001B[0m\n\u001B[1;32m     14\u001B[0m \u001B[38;5;66;03m# Epoch  5\ttrain accuracy: 0.8334\ttrain loss: 0.3875\u001B[39;00m\n\u001B[1;32m     15\u001B[0m \u001B[38;5;66;03m#             val accuracy: 0.7300\tval loss: 0.6310\u001B[39;00m\n",
      "Cell \u001B[0;32mIn[19], line 33\u001B[0m, in \u001B[0;36mreviews_train\u001B[0;34m(model, train_loader, val_loader, lr, epochs, max_norm, loss_fn)\u001B[0m\n\u001B[1;32m     31\u001B[0m \u001B[38;5;28;01mfor\u001B[39;00m epoch \u001B[38;5;129;01min\u001B[39;00m \u001B[38;5;28mrange\u001B[39m(epochs):\n\u001B[1;32m     32\u001B[0m     total_correct \u001B[38;5;241m=\u001B[39m total_loss \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m0\u001B[39m\n\u001B[0;32m---> 33\u001B[0m     \u001B[38;5;28;01mfor\u001B[39;00m reviews, labels \u001B[38;5;129;01min\u001B[39;00m train_loader:\n\u001B[1;32m     34\u001B[0m         model\u001B[38;5;241m.\u001B[39mtrain()\n\u001B[1;32m     36\u001B[0m         \u001B[38;5;66;03m# Send batch to your accelerator\u001B[39;00m\n",
      "File \u001B[0;32m~/PycharmProjects/Deep Learning/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:631\u001B[0m, in \u001B[0;36m_BaseDataLoaderIter.__next__\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    628\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_sampler_iter \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m:\n\u001B[1;32m    629\u001B[0m     \u001B[38;5;66;03m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001B[39;00m\n\u001B[1;32m    630\u001B[0m     \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_reset()  \u001B[38;5;66;03m# type: ignore[call-arg]\u001B[39;00m\n\u001B[0;32m--> 631\u001B[0m data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_next_data\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m    632\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m+\u001B[39m\u001B[38;5;241m=\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[1;32m    633\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_dataset_kind \u001B[38;5;241m==\u001B[39m _DatasetKind\u001B[38;5;241m.\u001B[39mIterable \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    634\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called \u001B[38;5;129;01mis\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m \u001B[38;5;28;01mNone\u001B[39;00m \u001B[38;5;129;01mand\u001B[39;00m \\\n\u001B[1;32m    635\u001B[0m         \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_num_yielded \u001B[38;5;241m>\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_IterableDataset_len_called:\n",
      "File \u001B[0;32m~/PycharmProjects/Deep Learning/.venv/lib/python3.9/site-packages/torch/utils/data/dataloader.py:675\u001B[0m, in \u001B[0;36m_SingleProcessDataLoaderIter._next_data\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    673\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21m_next_data\u001B[39m(\u001B[38;5;28mself\u001B[39m):\n\u001B[1;32m    674\u001B[0m     index \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_next_index()  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[0;32m--> 675\u001B[0m     data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_dataset_fetcher\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mfetch\u001B[49m\u001B[43m(\u001B[49m\u001B[43mindex\u001B[49m\u001B[43m)\u001B[49m  \u001B[38;5;66;03m# may raise StopIteration\u001B[39;00m\n\u001B[1;32m    676\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory:\n\u001B[1;32m    677\u001B[0m         data \u001B[38;5;241m=\u001B[39m _utils\u001B[38;5;241m.\u001B[39mpin_memory\u001B[38;5;241m.\u001B[39mpin_memory(data, \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_pin_memory_device)\n",
      "File \u001B[0;32m~/PycharmProjects/Deep Learning/.venv/lib/python3.9/site-packages/torch/utils/data/_utils/fetch.py:49\u001B[0m, in \u001B[0;36m_MapDatasetFetcher.fetch\u001B[0;34m(self, possibly_batched_index)\u001B[0m\n\u001B[1;32m     47\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mauto_collation:\n\u001B[1;32m     48\u001B[0m     \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mhasattr\u001B[39m(\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset, \u001B[38;5;124m\"\u001B[39m\u001B[38;5;124m__getitems__\u001B[39m\u001B[38;5;124m\"\u001B[39m) \u001B[38;5;129;01mand\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__:\n\u001B[0;32m---> 49\u001B[0m         data \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m__getitems__\u001B[49m\u001B[43m(\u001B[49m\u001B[43mpossibly_batched_index\u001B[49m\u001B[43m)\u001B[49m\n\u001B[1;32m     50\u001B[0m     \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m     51\u001B[0m         data \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m possibly_batched_index]\n",
      "File \u001B[0;32m~/PycharmProjects/Deep Learning/.venv/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001B[0m, in \u001B[0;36mSubset.__getitems__\u001B[0;34m(self, indices)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset[\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx]] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "File \u001B[0;32m~/PycharmProjects/Deep Learning/.venv/lib/python3.9/site-packages/torch/utils/data/dataset.py:399\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m    397\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mdataset\u001B[38;5;241m.\u001B[39m__getitems__([\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mindices[idx] \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices])  \u001B[38;5;66;03m# type: ignore[attr-defined]\u001B[39;00m\n\u001B[1;32m    398\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[0;32m--> 399\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mdataset\u001B[49m\u001B[43m[\u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mindices\u001B[49m\u001B[43m[\u001B[49m\u001B[43midx\u001B[49m\u001B[43m]\u001B[49m\u001B[43m]\u001B[49m \u001B[38;5;28;01mfor\u001B[39;00m idx \u001B[38;5;129;01min\u001B[39;00m indices]\n",
      "Cell \u001B[0;32mIn[2], line 55\u001B[0m, in \u001B[0;36mReviewsDataset.__getitem__\u001B[0;34m(self, idx)\u001B[0m\n\u001B[1;32m     53\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_labels[idx]        \n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab:\n\u001B[0;32m---> 55\u001B[0m     review_ids \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab\u001B[38;5;241m.\u001B[39mget_stoi()[token] \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m review]\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m review_ids, label\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "Cell \u001B[0;32mIn[2], line 55\u001B[0m, in \u001B[0;36m<listcomp>\u001B[0;34m(.0)\u001B[0m\n\u001B[1;32m     53\u001B[0m label \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_labels[idx]        \n\u001B[1;32m     54\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mvocab:\n\u001B[0;32m---> 55\u001B[0m     review_ids \u001B[38;5;241m=\u001B[39m [\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_stoi\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m[token] \u001B[38;5;28;01mfor\u001B[39;00m token \u001B[38;5;129;01min\u001B[39;00m review]\n\u001B[1;32m     56\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m review_ids, label\n\u001B[1;32m     57\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n",
      "File \u001B[0;32m~/PycharmProjects/Deep Learning/.venv/lib/python3.9/site-packages/torchtext/vocab/vocab.py:150\u001B[0m, in \u001B[0;36mVocab.get_stoi\u001B[0;34m(self)\u001B[0m\n\u001B[1;32m    144\u001B[0m \u001B[38;5;129m@torch\u001B[39m\u001B[38;5;241m.\u001B[39mjit\u001B[38;5;241m.\u001B[39mexport\n\u001B[1;32m    145\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mget_stoi\u001B[39m(\u001B[38;5;28mself\u001B[39m) \u001B[38;5;241m-\u001B[39m\u001B[38;5;241m>\u001B[39m Dict[\u001B[38;5;28mstr\u001B[39m, \u001B[38;5;28mint\u001B[39m]:\n\u001B[1;32m    146\u001B[0m \u001B[38;5;250m    \u001B[39m\u001B[38;5;124mr\u001B[39m\u001B[38;5;124;03m\"\"\"\u001B[39;00m\n\u001B[1;32m    147\u001B[0m \u001B[38;5;124;03m    Returns:\u001B[39;00m\n\u001B[1;32m    148\u001B[0m \u001B[38;5;124;03m        Dictionary mapping tokens to indices.\u001B[39;00m\n\u001B[1;32m    149\u001B[0m \u001B[38;5;124;03m    \"\"\"\u001B[39;00m\n\u001B[0;32m--> 150\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mvocab\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mget_stoi\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "\u001B[0;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "execution_count": 20
  },
  {
   "cell_type": "markdown",
   "id": "b25b9cc4",
   "metadata": {},
   "source": [
    "## Task 4: Pre-trained Embeddings & Visualization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad1c8ce5",
   "metadata": {},
   "source": [
    "### Task 4b"
   ]
  },
  {
   "cell_type": "code",
   "id": "3e0d4516",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Load Glove embeddings into a plain embedding layer.\n",
    "vocab = dataset.vocab\n",
    "glove_embeddings = nn.Embedding(len(vocab), 100, device=DEVICE)\n",
    "reviews_load_embeddings(glove_embeddings, vocab.get_stoi())"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "694aece7",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Print one embedding\n",
    "glove_embeddings(torch.tensor(vocab[\"movie\"], device=DEVICE))"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f783e3f8",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# Plot embeddings of first 100 words using t-SNE\n",
    "nextplot()\n",
    "_ = tsne_vocab(glove_embeddings, torch.arange(100), vocab)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "f531b640",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# You can also specify colors and/or drop the item labels\n",
    "nextplot()\n",
    "_ = tsne_vocab(glove_embeddings, torch.arange(100), colors=[0] * 50 + [1] * 50)"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "# Note: you can obtain the embeddings tensor using glove_embeddings.weight.data\n",
    "embeddings_tensor = glove_embeddings.weight.data\n",
    "\n",
    "def plot_tsne(embeddings, words, colors=None):\n",
    "    tsne = TSNE(n_components=2, perplexity=30, n_iter=1000, metric='cosine')\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure()\n",
    "    if colors:\n",
    "        plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors)\n",
    "    else:\n",
    "        plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "\n",
    "    for i, word in enumerate(words):\n",
    "        plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[i, 1]))\n",
    "\n",
    "    plt.xlabel(\"t-SNE Dimension 1\")\n",
    "    plt.ylabel(\"t-SNE Dimension 2\")\n",
    "    plt.title(\"t-SNE Visualization of GloVe Embeddings\")\n",
    "    plt.show()\n",
    "\n",
    "subset_words = vocab.get_itos()\n",
    "subset_words = [subset_words[i] for i in range(100)]\n",
    "\n",
    "plot_tsne(embeddings_tensor[:100], subset_words)"
   ],
   "id": "ca83cdb871c9b3e2",
   "outputs": [],
   "execution_count": null
  },
  {
   "metadata": {
    "jupyter": {
     "is_executing": true
    }
   },
   "cell_type": "code",
   "source": [
    "import umap.umap_ as umap\n",
    "\n",
    "def plot_umap(embeddings, words, colors=None):\n",
    "  \"\"\"\n",
    "  Visualizes word embeddings using UMAP for dimensionality reduction.\n",
    "  \"\"\"\n",
    "  mapper = umap.UMAP(n_components=2)  # Reduce to 2D\n",
    "  embeddings_2d = mapper.fit_transform(embeddings)\n",
    "\n",
    "  plt.figure()\n",
    "  if colors:\n",
    "      plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors)\n",
    "  else:\n",
    "      plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1])\n",
    "\n",
    "  for i, word in enumerate(words):\n",
    "      plt.annotate(word, (embeddings_2d[i, 0], embeddings_2d[:, 1]))\n",
    "\n",
    "  plt.xlabel(\"UMAP Dimension 1\")\n",
    "  plt.ylabel(\"UMAP Dimension 2\")\n",
    "  plt.title(\"UMAP Visualization of GloVe Embeddings\")\n",
    "  plt.show()\n",
    "\n",
    "# Example usage with UMAP\n",
    "subset_words = vocab.get_itos()\n",
    "subset_words = subset_words[:100]  # Select first 100 words\n",
    "\n",
    "plot_umap(embeddings_tensor[:100], subset_words)"
   ],
   "id": "ffdce914723942c1",
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "markdown",
   "id": "ee6438e5",
   "metadata": {},
   "source": [
    "### Task 4c"
   ]
  },
  {
   "cell_type": "code",
   "id": "e91dbc24",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# hyperparameter settings for rest of task 4\n",
    "vocab_size = len(dataset.vocab)\n",
    "embedding_dim = 100\n",
    "hidden_dim = 100\n",
    "num_layers = 2\n",
    "n_epochs = 10\n",
    "cell_dropout = 0.0"
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "id": "fa09c5d6",
   "metadata": {
    "collapsed": false,
    "jupyter": {
     "is_executing": true
    }
   },
   "source": [
    "# train a plain model\n",
    "model = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, cell_dropout).to(\n",
    "    DEVICE\n",
    ")\n",
    "reviews_train(model, train_loader, val_loader, epochs=n_epochs)\n",
    "\n",
    "# Should reach a (train) accuracy of >0.9. If not, rerun."
   ],
   "outputs": [],
   "execution_count": null
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1235b7f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot t-SNE embeddings of the thought vectors for training data\n",
    "# point color = label\n",
    "nextplot()\n",
    "_ = tsne_thought(model, train_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b18c68dd",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot t-SNE embeddings of of the thought vectors for validation data\n",
    "nextplot()\n",
    "_ = tsne_thought(model, val_loader, DEVICE)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b1cab379",
   "metadata": {},
   "source": [
    "### Task 4d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e27fa220",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the model with *p*re-trained embeddings with *f*inetuning, then train\n",
    "model_pf = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, cell_dropout)\n",
    "reviews_load_embeddings(model_pf.embedding, vocab.get_stoi())\n",
    "reviews_train(model_pf, train_loader, val_loader, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4fea5029",
   "metadata": {},
   "source": [
    "### Task 4e"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6925c415",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Initialize the model with *p*re-trained embeddings without finetuning, then train\n",
    "model_p = SimpleLSTM(vocab_size, embedding_dim, hidden_dim, num_layers, cell_dropout)\n",
    "reviews_load_embeddings(model_p.embedding, vocab.get_stoi())\n",
    "model_p.embedding.weight.requires_grad = False\n",
    "reviews_train(model_p, train_loader, val_loader, epochs=n_epochs)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0c2c3b7",
   "metadata": {},
   "source": [
    "## Task 5: Exploration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d817852d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# YOUR CODE HERE"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
