{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1c11c80a",
   "metadata": {},
   "source": [
    "# Assignment 3: Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "code",
   "id": "21a4662b",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T18:42:44.949881Z",
     "start_time": "2024-05-15T18:42:42.354392Z"
    }
   },
   "source": [
    "import torch\n",
    "from torch import nn, optim\n",
    "\n",
    "import torch.nn.functional as F\n",
    "import lightning as L\n",
    "from lightning.pytorch import seed_everything\n",
    "from lightning.pytorch.loggers import TensorBoardLogger\n",
    "from lightning.pytorch.callbacks import EarlyStopping\n",
    "from torchvision.datasets import CIFAR10\n",
    "from torchvision.transforms import v2\n",
    "from torch.utils.data import random_split, DataLoader\n",
    "import matplotlib.pyplot as plt\n",
    "from math import floor\n",
    "import sys, os\n",
    "\n",
    "sys.path.append(os.getcwd())\n",
    "from a03helper import *\n",
    "\n",
    "seed_everything(42)"
   ],
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Seed set to 42\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "42"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "execution_count": 1
  },
  {
   "cell_type": "markdown",
   "id": "ef95c042",
   "metadata": {},
   "source": [
    "## Task 1: Simple CNN"
   ]
  },
  {
   "cell_type": "code",
   "id": "a4dda22f",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-05-15T18:44:46.581871Z",
     "start_time": "2024-05-15T18:44:46.570736Z"
    }
   },
   "source": [
    "class ConvBlock(nn.Module):\n",
    "    \"\"\"A convolution block as used in the CS231n web demo.\"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_channels=3,\n",
    "        intermediate_channels=16,\n",
    "        out_channels=16,\n",
    "        conv_kernel_size=3,\n",
    "        pool_kernel_size=2,\n",
    "        activation_fn=F.relu,\n",
    "    ):\n",
    "        super().__init__()\n",
    "\n",
    "        # Define the individual layers here:\n",
    "        # First convolution:  self.conv1\n",
    "        # Second convolution: self.conv2\n",
    "        # Max-pooling:        self.pool\n",
    "        # Activation function: self.activation_fn\n",
    "        self.conv1 = nn.Conv2d(in_channels, intermediate_channels, conv_kernel_size, padding='same', stride=1)\n",
    "        self.conv2 = nn.Conv2d(intermediate_channels, out_channels, conv_kernel_size, padding='same', stride=1)\n",
    "        self.pool = nn.MaxPool2d(pool_kernel_size, stride=2)\n",
    "        self.activation_fn = activation_fn\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        # Note that inputs have shape: batch size x channels x width x height\n",
    "        out = self.conv1(x)\n",
    "        out = self.activation_fn(out)\n",
    "        out = self.conv2(out)\n",
    "        out = self.activation_fn(out)\n",
    "        out = self.pool(out)\n",
    "        return out\n",
    "\n",
    "\n",
    "# Images of the CIFAR-10 dataset are of shape:\n",
    "# [color_channels, height, width] = [3, 32, 32]\n",
    "batch = torch.randn(2, 3, 32, 32)\n",
    "block = ConvBlock()\n",
    "batch_out = block(batch)\n",
    "print(batch_out.shape)\n",
    "\n",
    "\n",
    "# Should yield:\n",
    "# torch.Size([2, 16, 16, 16])"
   ],
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([2, 16, 16, 16])\n"
     ]
    }
   ],
   "execution_count": 3
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4e64ea7d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class SimpleCNN(nn.Module):\n",
    "    def __init__(\n",
    "        self,\n",
    "        num_conv_blocks=3,\n",
    "        conv_out_channels=16,\n",
    "        conv_kernel_size=3,\n",
    "        activation_fn=F.relu,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        # Store conv blocks inside this module list (will used later). To do so, use the\n",
    "        # append() method.\n",
    "        self.conv_blocks = nn.ModuleList()\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # Output the softmax scores (i.e., do not apply the softmax function) for the\n",
    "        # images in the batch\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4f8d03c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test your implementation\n",
    "model = SimpleCNN()\n",
    "batch = torch.randn(2, 3, 32, 32)\n",
    "batch_out = model(batch)\n",
    "print(batch_out)\n",
    "\n",
    "\n",
    "# Should yield an ouput such as:\n",
    "# tensor([[-0.0433, -0.0400,  0.0532,  0.0348, -0.0274,  0.0176, -0.0505,  0.0557,\n",
    "#           0.0335,  0.0585],\n",
    "#         [-0.0425, -0.0385,  0.0518,  0.0349, -0.0263,  0.0188, -0.0502,  0.0548,\n",
    "#           0.0329,  0.0582]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5989a65e",
   "metadata": {},
   "source": [
    "## Task 2: Lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c12ca13e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LitBaseCNN(L.LightningModule):\n",
    "    def __init__(self, lr=0.001, **kwargs):\n",
    "        super().__init__()\n",
    "        self.model = self.initialize_model(**kwargs)\n",
    "        self.lr = lr\n",
    "\n",
    "    def initialize_model(self, **kwargs):\n",
    "        \"\"\"\n",
    "        This method will be implemented later on. Do not change.\n",
    "        \"\"\"\n",
    "        raise NotImplementedError(\"method 'initialize_model' not implemented\")\n",
    "\n",
    "    def configure_optimizers(self):\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass\n",
    "\n",
    "    def training_step(self, batch, batch_idx):\n",
    "        # TODO YOUR CODE HERE\n",
    "        # In addition to returning the training loss, also log it as 'train_loss'.\n",
    "        pass\n",
    "\n",
    "    def validation_step(self, batch, batch_idx):\n",
    "        return self._eval(batch, mode=\"val\")\n",
    "\n",
    "    def test_step(self, batch, batch_idx):\n",
    "        return self._eval(batch, \"test\")\n",
    "\n",
    "    def _eval(self, batch, mode=\"val\"):\n",
    "        \"\"\"\n",
    "        This method is used both for validation and testing\n",
    "        (cf. validation_step and test_step).\n",
    "        \"\"\"\n",
    "        # TODO YOUR CODE HERE\n",
    "        # Log the loss as `{mode}_loss`, the accuracy as\n",
    "        # `{mode}_acc` and additionally as `hp_metric`.\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "354267c5",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LitSimpleCNN(LitBaseCNN):\n",
    "    def initialize_model(\n",
    "        self,\n",
    "        num_conv_blocks=3,\n",
    "        conv_out_channels=16,\n",
    "        conv_kernel_size=3,\n",
    "        activation_fn=F.relu,\n",
    "    ):\n",
    "        return SimpleCNN(\n",
    "            num_conv_blocks, conv_out_channels, conv_kernel_size, activation_fn\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dbcc8007",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "simple_cnn = LitSimpleCNN(num_conv_blocks=2, conv_out_channels=16)\n",
    "print(simple_cnn)\n",
    "\n",
    "# Should produce:\n",
    "# LitSimpleCNN(\n",
    "#   (model): SimpleCNN(\n",
    "#     (conv_blocks): ModuleList(\n",
    "#       (0): ConvBlock(\n",
    "#         (conv1): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
    "#         (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
    "#         (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#       )\n",
    "#       (1): ConvBlock(\n",
    "#         (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
    "#         (conv2): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
    "#         (pool): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
    "#       )\n",
    "#     )\n",
    "#     (linear): Linear(in_features=1024, out_features=10, bias=True)\n",
    "#   )\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3116dcd9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is how to use the model manually\n",
    "# (alternatively, implement a forward() method, see\n",
    "# https://lightning.ai/docs/pytorch/stable/common/lightning_module.html#inference-in-research ).\n",
    "batch = torch.randn(2, 3, 32, 32)\n",
    "model = LitSimpleCNN().model\n",
    "batch_out = model(batch)\n",
    "print(batch_out)\n",
    "\n",
    "\n",
    "# Should yield:\n",
    "# tensor([[ 0.0347,  0.0706,  0.0101, -0.0390,  0.0411, -0.0452, -0.0055,  0.0297,\n",
    "#          -0.0663, -0.0240],\n",
    "#         [ 0.0339,  0.0697,  0.0110, -0.0393,  0.0408, -0.0444, -0.0060,  0.0294,\n",
    "#          -0.0650, -0.0240]], grad_fn=<AddmmBackward0>)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7e1215ba",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class CifarDataModule(L.LightningDataModule):\n",
    "    def __init__(self, data_dir=\"raw\", batch_size=32, num_workers=0):\n",
    "        super().__init__()\n",
    "        self.data_dir = data_dir\n",
    "        self.batch_size = batch_size\n",
    "        self.num_workers = num_workers\n",
    "\n",
    "    def prepare_data(self):\n",
    "        # This downloads the data if not yet present, but does not yet associate it with\n",
    "        # this module (see documentation).\n",
    "        CIFAR10(self.data_dir, train=True, download=True)\n",
    "        CIFAR10(self.data_dir, train=False, download=True)\n",
    "\n",
    "    def setup(self, stage: str):\n",
    "        transforms = v2.Compose(\n",
    "            [\n",
    "                v2.ToImage(),\n",
    "                v2.ToDtype(torch.float32, scale=True),\n",
    "                v2.Normalize(\n",
    "                    (0.4913, 0.4821, 0.4465),\n",
    "                    (0.2470, 0.2434, 0.2615),\n",
    "                ),\n",
    "            ]\n",
    "        )\n",
    "\n",
    "        if stage == \"fit\":\n",
    "            # This loads the training data\n",
    "            cifar_train = CIFAR10(self.data_dir, True, transforms)\n",
    "\n",
    "            # TODO YOUR CODE HERE\n",
    "            # Split training data into 80% training and 20% validation data and assign\n",
    "            # to self.train_data and self.val_data\n",
    "\n",
    "        elif stage == \"test\":\n",
    "            # This loads the test data\n",
    "            self.test_data = CIFAR10(self.data_dir, False, transforms)\n",
    "\n",
    "    def train_dataloader(self):\n",
    "        # TODO YOUR CODE HERE\n",
    "        # Return train dataloader with `self.batch_size` and `self.num_workers`\n",
    "        # and shuffling enabled.\n",
    "        pass\n",
    "\n",
    "    def val_dataloader(self):\n",
    "        # TODO YOUR CODE HERE\n",
    "        # Return validation dataloader with `self.batch_size` and `self.num_workers`.\n",
    "        pass\n",
    "\n",
    "    def test_dataloader(self):\n",
    "        # TODO YOUR CODE HERE\n",
    "        # Return test dataloader with `self.batch_size` and `self.num_workers`.\n",
    "        pass\n",
    "\n",
    "\n",
    "dm = CifarDataModule()\n",
    "dm.prepare_data()\n",
    "dm.setup(\"fit\")\n",
    "print(len(dm.train_dataloader().dataset))\n",
    "# Should yield:\n",
    "# 40000"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cb03c5da",
   "metadata": {},
   "source": [
    "## Task 3: Training with Lightning and TensorBoard"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a9454f4",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Define hyperparameters (hp) and initialize modules\n",
    "model_hp = dict(\n",
    "    num_conv_blocks=3,\n",
    "    conv_out_channels=16,\n",
    "    conv_kernel_size=5,\n",
    "    activation_fn=F.relu,\n",
    "    lr=0.001,\n",
    ")\n",
    "other_hp = dict(\n",
    "    batch_size=32,\n",
    "    max_epochs=4,\n",
    ")\n",
    "simple_cnn = LitSimpleCNN(**model_hp)\n",
    "dm = CifarDataModule(batch_size=other_hp[\"batch_size\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b25ad78c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Log hyperparameters using TensorBoard\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"logs\", name=\"simple_cnn\"\n",
    ")  # do not change location in JHub\n",
    "logger.log_hyperparams({**model_hp, **other_hp})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f7cb9614",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Create a trainer\n",
    "trainer = L.Trainer(\n",
    "    deterministic=True,\n",
    "    fast_dev_run=True,  # change this to False for actual training\n",
    "    max_epochs=other_hp[\"max_epochs\"],\n",
    "    logger=logger,\n",
    "    check_val_every_n_epoch=1,\n",
    "    # TODO YOUR CODE HERE\n",
    "    # add early stopping\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c55db5d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# And run it\n",
    "trainer.fit(simple_cnn, datamodule=dm)\n",
    "# Should yield an accuracy of 65 % after 4 epochs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6988d7d4",
   "metadata": {},
   "source": [
    "### TensorBoard\n",
    "\n",
    "There are a few options to run TensorBoard depending on your environment.\n",
    "\n",
    "#### Jupyter Hub\n",
    "\n",
    "Open up a new tab inside JupyterHub. Then, open TensorBoard.\n",
    "\n",
    "#### Local environment\n",
    "\n",
    "Open a shell inside this directory. Run:\n",
    "\n",
    "```sh\n",
    "tensorboard --logdir logs\n",
    "```\n",
    "\n",
    "Then, open your browser and navigate to: [http://localhost:6006](http://localhost:6006)\n",
    "\n",
    "#### Docker Container\n",
    "\n",
    "Open a shell inside your running container:\n",
    "\n",
    "```sh\n",
    "docker exec -it <container> /bin/bash\n",
    "```\n",
    "where the container can be identified using `docker ps`. From there, proceed as\n",
    "in a local environment (see above).\n",
    "\n",
    "#### Inside Jupyter (but not on Jupyter Hub)\n",
    "\n",
    "Create a new code cell with the following contents and execute:\n",
    "\n",
    "```sh\n",
    "%load_ext tensorboard\n",
    "%tensorboard --logdir logs\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7859c173",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# This is how you would use the test dataset (after you are done with your model\n",
    "# selection):\n",
    "trainer.test(simple_cnn, datamodule=dm)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2d24657d",
   "metadata": {},
   "source": [
    "## Task 4: Visualization\n",
    "\n",
    "model = LitSimpleCNN.load_from_checkpoint(\n",
    "    os.path.join(\"checkpoints\", \"simple-cnn.ckpt\"),\n",
    "    num_conv_blocks=2,\n",
    "    conv_out_channels=30,\n",
    "    conv_kernel_size=4,\n",
    "    lr=0.001,\n",
    ")\n",
    "trainer.test(model, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b3a0ff26",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain images from CIFAR-10 dataset\n",
    "dm.setup(\"fit\")\n",
    "train_data = dm.train_data\n",
    "\n",
    "# Plot the first 12 images\n",
    "fig, axs = plt.subplots(nrows=3, ncols=4)\n",
    "for i in range(12):\n",
    "    row = floor(i / 4)\n",
    "    col = i % 4\n",
    "    axs[row, col].imshow(train_data[i][0].permute(1, 2, 0))\n",
    "    axs[row, col].set_title(i)\n",
    "    axs[row, col].axis(\"off\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ec2f717e",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain first block's output of a single image and plot\n",
    "item, label = train_data[7]  # choose the image that you find most promising to analyze\n",
    "block0 = simple_cnn.model.conv_blocks[0].cpu()\n",
    "with torch.no_grad():\n",
    "    out0 = block0(item)\n",
    "plot_conv_module_output(out0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "459e216c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Obtain second's block output for the same image and plot\n",
    "block1 = simple_cnn.model.conv_blocks[1].cpu()\n",
    "with torch.no_grad():\n",
    "    out1 = block1(out0)\n",
    "plot_conv_module_output(out1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c8e0f2d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot filters from first convolutional layer (columns refer to input channels, rows\n",
    "# output channels)\n",
    "conv1 = block0.conv1.weight.detach()\n",
    "plot_kernels(conv1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2a308a0c",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Plot filters from second convolutional layer\n",
    "conv1 = block0.conv2.weight.detach()\n",
    "plot_kernels(conv1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72808939",
   "metadata": {},
   "source": [
    "## Task 5: ConvNeXt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fd3a8e27",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LayerNormChannels(nn.Module):\n",
    "    \"\"\"Utility module for the layer norms.\"\"\"\n",
    "\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        self.norm = nn.LayerNorm(C)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x1 = x.transpose(1, -1)\n",
    "        x2 = self.norm(x1)\n",
    "        x3 = x2.transpose(-1, 1)\n",
    "        return x3\n",
    "\n",
    "\n",
    "batch = torch.randn(2, 3, 32, 32)\n",
    "norm_module = LayerNormChannels(3)\n",
    "batch_out = norm_module(batch)\n",
    "print(batch_out.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf967b1d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvNeXtBlock(nn.Module):\n",
    "    def __init__(self, C, conv_kernel_size):\n",
    "        super().__init__()\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "474494f7",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvNextDownsample(nn.Module):\n",
    "    def __init__(self, C):\n",
    "        super().__init__()\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dde86ca6",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvNeXtStem(nn.Module):\n",
    "    def __init__(self, in_channels=3, D=16, conv_kernel_size=3):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46f448e9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvNeXtStage(nn.Module):\n",
    "    def __init__(self, C, conv_kernel_size, downsample=True):\n",
    "        super().__init__()\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6eeb2f05",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class ConvNeXt(nn.Module):\n",
    "    def __init__(self, D=16, conv_kernel_size=3, num_stages=2):\n",
    "        super().__init__()\n",
    "\n",
    "        # TODO YOUR CODE HERE\n",
    "\n",
    "    def forward(self, x):\n",
    "        # TODO YOUR CODE HERE\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4c6f7ebe",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model = ConvNeXt(D=16)\n",
    "print(model)\n",
    "# Should yield:\n",
    "# ConvNeXt(\n",
    "#   (stem): ConvNeXtStem(\n",
    "#     (conv): Conv2d(3, 16, kernel_size=(3, 3), stride=(1, 1), padding=same)\n",
    "#   )\n",
    "#   (stages): ModuleList(\n",
    "#     (0): ConvNeXtStage(\n",
    "#       (stage): Sequential(\n",
    "#         (0): Identity()\n",
    "#         (1): ConvNeXtBlock(\n",
    "#           (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=16)\n",
    "#           (layer_norm): LayerNormChannels(\n",
    "#             (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
    "#           )\n",
    "#           (conv2): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "#           (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
    "#         )\n",
    "#         (2): ConvNeXtBlock(\n",
    "#           (conv1): Conv2d(16, 16, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=16)\n",
    "#           (layer_norm): LayerNormChannels(\n",
    "#             (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
    "#           )\n",
    "#           (conv2): Conv2d(16, 64, kernel_size=(1, 1), stride=(1, 1))\n",
    "#           (conv3): Conv2d(64, 16, kernel_size=(1, 1), stride=(1, 1))\n",
    "#         )\n",
    "#       )\n",
    "#     )\n",
    "#     (1): ConvNeXtStage(\n",
    "#       (stage): Sequential(\n",
    "#         (0): ConvNextDownsample(\n",
    "#           (layer_norm): LayerNormChannels(\n",
    "#             (norm): LayerNorm((16,), eps=1e-05, elementwise_affine=True)\n",
    "#           )\n",
    "#           (conv): Conv2d(16, 32, kernel_size=(2, 2), stride=(2, 2))\n",
    "#         )\n",
    "#         (1): ConvNeXtBlock(\n",
    "#           (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=32)\n",
    "#           (layer_norm): LayerNormChannels(\n",
    "#             (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
    "#           )\n",
    "#           (conv2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
    "#           (conv3): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
    "#         )\n",
    "#         (2): ConvNeXtBlock(\n",
    "#           (conv1): Conv2d(32, 32, kernel_size=(3, 3), stride=(1, 1), padding=same, groups=32)\n",
    "#           (layer_norm): LayerNormChannels(\n",
    "#             (norm): LayerNorm((32,), eps=1e-05, elementwise_affine=True)\n",
    "#           )\n",
    "#           (conv2): Conv2d(32, 128, kernel_size=(1, 1), stride=(1, 1))\n",
    "#           (conv3): Conv2d(128, 32, kernel_size=(1, 1), stride=(1, 1))\n",
    "#         )\n",
    "#       )\n",
    "#     )\n",
    "#   )\n",
    "#   (linear): Linear(in_features=8192, out_features=10, bias=True)\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a391a2d",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "batch = torch.randn(2, 3, 32, 32)\n",
    "batch_out = model(batch)\n",
    "print(batch_out.shape)\n",
    "\n",
    "\n",
    "# Should yield:\n",
    "# torch.Size([2, 10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "106c7941",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "class LitConvNeXt(LitBaseCNN):\n",
    "    def initialize_model(self, C, conv_kernel_size, num_stages):\n",
    "        return ConvNeXt(\n",
    "            C,\n",
    "            conv_kernel_size,\n",
    "            num_stages,\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c0666710",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_hp = dict(\n",
    "    lr=0.001,\n",
    "    C=16,\n",
    "    conv_kernel_size=7,\n",
    "    num_stages=4,\n",
    ")\n",
    "\n",
    "lit_convnext = LitConvNeXt(**model_hp)\n",
    "\n",
    "other_hp = dict(\n",
    "    batch_size=32,\n",
    "    max_epochs=5,\n",
    ")\n",
    "\n",
    "dm = CifarDataModule(batch_size=other_hp[\"batch_size\"])\n",
    "\n",
    "logger = TensorBoardLogger(\n",
    "    save_dir=\"logs\", name=\"convnext\"\n",
    ")  # do not change directory in JHub\n",
    "logger.log_hyperparams({**model_hp, **other_hp})\n",
    "\n",
    "trainer = L.Trainer(\n",
    "    deterministic=True,\n",
    "    fast_dev_run=False,\n",
    "    max_epochs=other_hp[\"max_epochs\"],\n",
    "    logger=logger,\n",
    "    check_val_every_n_epoch=1,\n",
    ")\n",
    "trainer.fit(lit_convnext, datamodule=dm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "71c903a9",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "trainer.test(lit_convnext, datamodule=dm)\n",
    "# Should reach a bit less than 70% accuracy"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3 (ipykernel)"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
